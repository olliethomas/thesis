
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Chapter 1: Introduction &#8212; Fair Representations in the Data Domain</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="oliverthomas.ml/content/01_introduction/intro.html" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Chapter 2: Related Work" href="../02_background/background.html" />
    <link rel="prev" title="Preliminaries" href="../00_thesis_pages/preliminaries.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-170288604-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/pal-logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Fair Representations in the Data Domain</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Thesis
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00_thesis_pages/front_page.html">
   Front Matter
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../00_thesis_pages/preliminaries.html">
   Preliminaries
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Chapter 1: Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_background/background.html">
     Chapter 2: Related Work
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00_thesis_pages/content.html">
     Chapter 3: Content
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../00_thesis_pages/publications.html">
   Publications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_positive_action/intro.html">
     Chapter 4: An Algorithmic Framework for Positive Action
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_data_domain_fairness/intro.html">
     Chapter 5: Data Domain Fairness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05_null_sampling/intro.html">
     Chapter 6: Null-sampling for Fair and Invariant Representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../00_thesis_pages/conclusion.html">
   Conclusion
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08_conclusion/conclusion.html">
     Chapter 7: Conclusion
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../00_thesis_pages/appendix.html">
   Appendix
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../bib.html">
     Bibliography
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09_appendix/published.html">
   Publications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09_appendix/publications/positive_action.html">
     An Algorithmic Framework for Positive Action
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09_appendix/publications/dfritdd.html">
     Discovering Fair Representations in the Data Domain
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09_appendix/publications/nosinn.html">
     Null-Sampling for Invariant and Interpretable Representations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09_appendix/publications/lit_review.html">
     Literature Review (Year 1 Annual Review)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09_appendix/software.html">
   Software
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09_appendix/software/ethicml.html">
     EthicML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09_appendix/software/intervene.html">
     Casual Discovery Tool
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09_appendix/software/conduit.html">
     Conduit
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/01_introduction/intro.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        <a class="issues-button"
            href="https://github.com/olliethomas/thesis/issues/new?title=Issue%20on%20page%20%2Fcontent/01_introduction/intro.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/olliethomas/thesis/edit/master/content/01_introduction/intro.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problem-statement">
   Problem statement
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation-and-aims">
   Motivation and Aims
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#claims-and-contributions">
   Claims and contributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#thesis-outline">
   Thesis Outline
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Chapter 1: Introduction</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problem-statement">
   Problem statement
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation-and-aims">
   Motivation and Aims
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#claims-and-contributions">
   Claims and contributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#thesis-outline">
   Thesis Outline
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="math notranslate nohighlight">
\[\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}\]</div>
<div class="tex2jax_ignore mathjax_ignore section" id="chapter-1-introduction">
<h1>Chapter 1: Introduction<a class="headerlink" href="#chapter-1-introduction" title="Permalink to this headline">¶</a></h1>
<p>The increasing capability of machine learning (ML) models to perform well at specific tasks has led to their use in more consequential applications.
This increased consequence has in turn led to greater scrutiny, with particular concern about what it means for an algorithmic decision, recommendation, or prediction to be ‘fair’.
In response, the research community has begun investigating these questions which are grouped together under the term algorithmic fairness (AF).
This burgeoning field of algorithmic fairness has been the focus of a growing body of research, with a number of definitions being introduced to quantify and measure <em>un</em>-fair behaviour, which, as a research community we aim to minimise, or ideally, eradicate.
These definitions are often with respect to specific, legally protected characteristics that are observed alongside the features used for training an ML model, but cannot be used during inference.
Examples of these protected characteristics may include race, gender, age, or disability status, among others.</p>
<p>Although algorithmic fairness is a multi-faceted problem, this thesis investigates a specific instance of a general concern - that data can contain spurious correlations.
These are correlations that only appear in a subset of samples, but do not exist in the broader population.
Spurious correlations may be present in a subset of data used for training and validating an ML model, leading to a shortcut being exploited rather than a more complicated underlying true function being learnt.
This becomes particularly important when the spurious correlation is between the model target and a protected characteristic.
Examples of a model target for a classification task may be approval or not, for a hiring, loan or bail decision.
Simple rules such as ‘invite male candidates to interview for a vacancy’, or ‘offer higher loans to white applicants’ may perform well on the labelled training and validation data, but when deployed they may both perform poorly, and have the potential to cause significant harms to the population.
This specific type of spurious correlation, often referred to as <em>biased data</em>, is the source of concern in this thesis.
Biased data impacts performance and plays a large part in the trust afforded to ML-based systems.
The effect of this can have a significant impact, especially in the case of decisions that directly affect a person’s livelihood.</p>
<p>A promising approach to counteract biased data is by producing a fair representation (FR) as a pre-processing step.
In FR-learning, the aim is to produce a transformation of the data such that it still retains utility for a downstream task, but has been modified so that information about a protected characteristic of concern is either removed, or obfuscated to the point where a downstream model produces ‘fairer’ decisions by default.
The benefits of this approach are that the fairness-promoting aspect is isolated, allowing easier regulation, and allowing the process to be independent of other concerns.
However, this approach is not without drawbacks.
Completely removing some attributes while retaining utility is non-trivial;
the burden of responsibility to check for unfair behaviour can be inadvertently moved away from a downstream system;
and the data often becomes obscured when projected into an uninterpretable latent space, making intuitive assessment difficult.
Making progress in addressing some of these drawbacks may promote the adoption of fair representations and the benefits that they provide.</p>
<div class="section" id="problem-statement">
<h2>Problem statement<a class="headerlink" href="#problem-statement" title="Permalink to this headline">¶</a></h2>
<p>This thesis investigates fair representations of data and whether they can be used to provide additional insight into a system.
Can we retain the benefits of fair representations of data - an isolated and measurable fairness-inducing intervention - while making progress in overcoming the shortcomings?
The result should be a transformation of the data that increases the fairness of a post-hoc ML model by default, while retaining the utility of the original input, and still remaining as interpretable as the input data.</p>
<p>This desiderata poses the research question that is tackled in this thesis:
‘How can we make fair representations interpretable?’.
To approach this, I first develop a method that uses fair representations to interrogate the effect of a specific protected characteristic.
This will provide insight into the relationship between the feature of interest, the protected characteristic, and the remaining features.
I will demonstrate that this can be used to promote fairer outcomes without directly manipulating an existing decision system.</p>
<p>Secondly, I will demonstrate that fair representations can exist within the data domain itself.
This is not a trivial task.
The resulting output of the transformation should reside in the original feature space and retain useful information about features other than the protected characteristic.
In addition, the transformation should also obfuscate that particular feature.</p>
<p>Lastly, I will improve on this first attempt at producing fair representations in the data domain, introducing models based on alternative approaches to achieve a more robust outcome with improvements to the qualitative results.</p>
</div>
<div class="section" id="motivation-and-aims">
<h2>Motivation and Aims<a class="headerlink" href="#motivation-and-aims" title="Permalink to this headline">¶</a></h2>
<p>More data cataloguing human behaviour is being produced than ever before.
The broad aim of many applications is to use this data to make sensible predictions about future events.
These can be to assist the user by preempting their needs and queries, or to make decisions about the effectiveness and cohesion of potential hires.
Ideally, to do this, we would aim to have the total information that was available to the user.
However, this is not realistic.
Instead, we typically have <span class="math notranslate nohighlight">\(n\)</span> pairs of data, <span class="math notranslate nohighlight">\((x,y)\)</span> which form a dataset <span class="math notranslate nohighlight">\(D = \{(x_0, y_0), \dots, (x_n,y_n)\}\)</span>.
These pairs represent input features <span class="math notranslate nohighlight">\(x\)</span> from the set of possible values <span class="math notranslate nohighlight">\(\gX\)</span>, and outcomes <span class="math notranslate nohighlight">\(y\)</span> from the set of possible outcomes <span class="math notranslate nohighlight">\(\gY\)</span>.
If the data were total, then we would have all of the information necessary to emulate the true underlying mapping from <span class="math notranslate nohighlight">\(\gX\)</span> to <span class="math notranslate nohighlight">\(\gY\)</span>.
Instead, we are limited to obtaining, at most, data that can be recorded.
As such, the aim is not to reconstruct the ground-truth mapping, but instead produce an approximation.
Typically in ML we focus on finding an approximation function <span class="math notranslate nohighlight">\(f: x \rightarrow y\)</span> from the set of possible functions in the hypothesis space <span class="math notranslate nohighlight">\(\mathcal{F}: \gX \rightarrow \gY\)</span> that most accurately models this relationship (minimises the Empirical Risk).
However, recent works have questioned if this alone is the best criterion for success.
Instead, fairness-aware ML algorithms take into account additional information in the form of a protected characteristic, <span class="math notranslate nohighlight">\(s\)</span>, and seek to reduce the hypothesis space to functions that either don’t make use of <span class="math notranslate nohighlight">\(s\)</span> at all, or allow for a defined margin-of-error<a class="footnote-reference brackets" href="#id2" id="id1">1</a>.
An overview of related work that aims to achieve this is discussed in <a class="reference internal" href="../02_background/background.html#ch-related-work"><span class="std std-ref">Chapter 2: Related Work</span></a>.</p>
<p>One application for ML models is emulating current decision processes.
For tasks such as loan approval, decisions have traditionally been made by a number of decision makers employed for the task, each with their own thresholds, preferences, and biases.
In such a setting, the promise of automated decision systems is clear.
An automated system can process millions of applications incredibly quickly, is available at all times, and crucially, will be consistent in its decision making process.
However, there are drawbacks.
Any errors or inconsistencies in the logic learned from observing past behaviour have a greater chance of being exposed, and worse, perpetuated.
With such a system deployed, it is no longer possible to pass off inconsistent decision making as human error.
The challenge to produce a fair system might be difficult, but there is significant opportunity for improvement from any unconstrained system.
In such a system, making the outcome ‘fairer’ in any way can have a significant and practical impact, even if absolute fairness is not achieved.</p>
<p>One criticism that is often levelled at ML models, especially those deployed in human-centred scenarios, is that the decision making process is not clear.
In addition to our desire to produce fairer results, it is also important that stakeholders in the system feel confident in any fairness-enhancing interventions introduced.
On top of the aim of producing a fairer result, any amendments to the system should also increase the interpretability.
An improved fairness intervention solution would not only increase the fairness of the system, but would allow stakeholders to gain some knowledge of what changes are required for this to be met.</p>
<p>Lastly, a concern for generally adopting fair ML is the potential trade-off between model accuracy and how ‘fair’ the system is.
I explore more about different definitions of fairness in <a class="reference internal" href="../02_background/background.html#ch-related-work"><span class="std std-ref">Chapter 2: Related Work</span></a>, however there is a simple case to demonstrate that there may not be a trade-off after all.
In cref{1-intro:fig:imbalanced-s-skew} we witness the case where the training dataset is imbalanced in relation to the deployment setting.
This can be for a number of reasons, such as using historical data, or only having access to a limited source of data.
In the deployment set, however, the data is balanced.
If the features available to train a model are not sufficiently rich for a function to approximate the mapping of <span class="math notranslate nohighlight">\(\gX\)</span> to <span class="math notranslate nohighlight">\(\gY\)</span>, but are sufficiently rich to map <span class="math notranslate nohighlight">\(\gX\)</span> to <span class="math notranslate nohighlight">\(\gS\)</span>, then the the protected characteristic may become a <em>proxy label</em> for the target.
In this case, the data could be categorised as biased - there exists a spurious correlation between <span class="math notranslate nohighlight">\(s\)</span> and <span class="math notranslate nohighlight">\(y\)</span> that is only present in the training set.
By providing an additional inductive bias that the outcome should <em>not</em> be dependent on <span class="math notranslate nohighlight">\(s\)</span>, we may produce a function <span class="math notranslate nohighlight">\(f\)</span> that is closer to the ground truth than the training data implies.</p>
<p>INSERT PIC HERE</p>
<p>The aims of this thesis are to provide an approach that combats specific spurious correlations in the form of biased data.
I produce this at the <em>pre-processing</em> stage in the form of a data transformation.
While ideally a protected characteristic would be completely obfuscated, this is an unnecessary aim.
Instead, the task of deciphering the protected characteristic need only be more complex than learning to perform the task.</p>
<p>As an additional aim, the resulting transformation should give us some insight into the transformation process itself.
Of particular concern is additional problems being introduced by the transformation process.
For example, if the protected characteristic is ‘gender’, then any changes made to hide this feature that in turn affect skin-tone are an indicator that the system designer may also need to consider ‘race’ as an additional source of potential bias.
Similarly, if the system returns a clearly degenerate solution, then it may save months of development time by highlighting this problem earlier.</p>
</div>
<div class="section" id="claims-and-contributions">
<h2>Claims and contributions<a class="headerlink" href="#claims-and-contributions" title="Permalink to this headline">¶</a></h2>
<p>In this thesis, I produce three main contributions.
Firstly, I demonstrate that fair representations can be used to produce fairer outcomes for already existing systems.
I achieve this by drawing a connection between the reconstruction of samples from fair representations and counterfactual examples.
This work is catalogued in <a class="reference internal" href="../03_positive_action/intro.html#ch-paper1"><span class="std std-ref">Chapter 4: An Algorithmic Framework for Positive Action</span></a>.</p>
<p>Secondly, I demonstrate that fair representations can exist within the data domain, making use of the inherent interpretability that this domain provides.
I make a first contribution to this in <a class="reference internal" href="../04_data_domain_fairness/intro.html#ch-paper2"><span class="std std-ref">Chapter 5: Data Domain Fairness</span></a> using a statistical dependence measure to promote a fairer representation under an additive decomposition assumption, allowing the data to be broken down to a ‘fair’ and ‘unfair’ component.</p>
<p>Lastly, I improve on this first attempt, assuming a more complex relationship between the ‘fair’ and ‘unfair’ components and introduce <em>null-sampling</em> in <a class="reference internal" href="../05_null_sampling/intro.html#ch-paper3"><span class="std std-ref">Chapter 6: Null-sampling for Fair and Invariant Representations</span></a> to draw manipulated samples from a designated region of a learned latent space.
This opens up alternative techniques to achieve fair representations in the data domain, making use of the properties of both a conditional Variational Auto Encoder (VAE) and an Invertible Neural Network (INN).</p>
</div>
<div class="section" id="thesis-outline">
<h2>Thesis Outline<a class="headerlink" href="#thesis-outline" title="Permalink to this headline">¶</a></h2>
<p>This thesis is organised in the following way.
<span class="xref std std-ref">ch:related-work</span> gives an overview of algorithmic fairness, and in particular, publications to date on fair representations of data.
Following this, <a class="reference internal" href="../00_thesis_pages/content.html#ch-content"><span class="std std-ref">Chapter 3: Content</span></a> describes each of the three main chapters of this thesis in greater detail, with an emphasis on how they relate to each other.
<a class="reference internal" href="../03_positive_action/intro.html#ch-paper1"><span class="std std-ref">Chapter 3</span></a>-<a class="reference internal" href="../05_null_sampling/intro.html#ch-paper3"><span class="std std-ref">Chapter 5</span></a> contain three peer-reviewed and published works which have been reproduced with minimal changes except where explicitly indicated.
The work presented in <a class="reference internal" href="../03_positive_action/intro.html#ch-paper1"><span class="std std-ref">Chapter 4: An Algorithmic Framework for Positive Action</span></a> is currently under review at <strong>a journal</strong>, however the conference proceedings on which the journal submission is based can be found in <span class="xref std std-ref">app:paper1</span>.
<a class="reference internal" href="../04_data_domain_fairness/intro.html#ch-paper2"><span class="std std-ref">Chapter 5: Data Domain Fairness</span></a> contains an addendum with experimental results to help motivate <a class="reference internal" href="../05_null_sampling/intro.html#ch-paper3"><span class="std std-ref">Chapter 6: Null-sampling for Fair and Invariant Representations</span></a>.
Finally, in <a class="reference internal" href="../00_thesis_pages/conclusion.html#ch-conclusion"><span class="std std-ref">Conclusion</span></a> I present the main conclusions and suggest possible future directions for the presented work.</p>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="id2"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>The maximum margin-of-error is often legally defined.</p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/01_introduction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../00_thesis_pages/preliminaries.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Preliminaries</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../02_background/background.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 2: Related Work</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Oliver Thomas<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>