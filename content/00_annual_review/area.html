

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Research Area &amp; Question &#8212; Fair Representations of Biased Data</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="canonical" href="oliverthomas.ml/content/00_annual_review/area.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Activities to date" href="activities_to_date.html" />
    <link rel="prev" title="Summary" href="summary.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">


<!-- Opengraph tags -->
<meta property="og:url"         content="oliverthomas.ml/content/00_annual_review/area.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Research Area & Question" />
<meta property="og:description" content="Research Area & Question  Research Area  Machine Learning is a tool that is growing in popularity. There have been a number of high profile successes, and new a" />
<meta property="og:image"       content="oliverthomas.ml/_static/pal-logo.png" />

<meta name="twitter:card" content="summary">


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/pal-logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Fair Representations of Biased Data</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../index.html">Fair Representations of Biased Data</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Annual Review 2020</p>
</li>
  <li class="active">
    <a href="summary.html">Summary</a>
  <ul class="nav sidenav_l2">
    <li class="active">
      <a href="">Research Area & Question</a>
    </li>
  </ul>
  </li>
  <li class="">
    <a href="activities_to_date.html">Activities to date</a>
  </li>
  <li class="">
    <a href="structure.html">Thesis Structure</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Appendix</p>
</li>
  <li class="">
    <a href="../09_appendix/dfritdd.html">Discovering Fair Representations in the Data Domain</a>
  </li>
  <li class="">
    <a href="../09_appendix/imagined.html">Imagined Examples for Fairness: Sampling Bias and Proxy Labels</a>
  </li>
  <li class="">
    <a href="../09_appendix/nosinn.html">Null-Sampling for Invariant and Interpretable Representations</a>
  </li>
  <li class="">
    <a href="../09_appendix/invisible.html">Invisible Demographics</a>
  </li>
  <li class="">
    <a href="../09_appendix/lit_review.html">Literature Review (Year 1 Annual Review)</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/00_annual_review/area.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        <a class="issues-button"
            href="https://github.com/olliethomas/thesis/issues/new?title=Issue%20on%20page%20%2Fcontent/00_annual_review/area.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/olliethomas/thesis/edit/master/content/00_annual_review/area.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#research-area" class="nav-link">Research Area</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#fair-machine-learning" class="nav-link">Fair Machine Learning</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#research-question" class="nav-link">Research Question</a>
        </li>
    
    </ul>
</nav>



<div class="tocsection editthispage">
    <a href="https://github.com/olliethomas/thesis/edit/master/content/00_annual_review/area.md">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="research-area-question">
<h1>Research Area &amp; Question<a class="headerlink" href="#research-area-question" title="Permalink to this headline">¶</a></h1>
<div class="section" id="research-area">
<h2>Research Area<a class="headerlink" href="#research-area" title="Permalink to this headline">¶</a></h2>
<p>Machine Learning is a tool that is growing in popularity.
There have been a number of high profile successes, and new applications are being regularly identified.
These applications include translation (in both image and natural-language domains), pattern recognition and decision-making.
Contexts for these applications include Geology, Meteorology, Sports forecasting and Agriculture, to name a few.</p>
<p>Because of this success there is a desire to incorporate these systems in more and more situations, including those directly applicable to people.
For example, Machine Learning systems have already been applied to police allocation, recidivism prediction, candidate screening and credit approval.</p>
<p>On top of the benefits of automated decision making (speed, scale, etc) there is an additional promise to automated decisions.
The promise is that instead of many human decision makers, each one biased with their own prejudices, heuristics and experience, we can have a uniform approach.
The hope is that by treating everybody the same, then unequal, biased behaviour can be removed.</p>
<p>Unfortunately, that’s not always the case.</p>
<p>Recent headlines include:</p>
<ul class="simple">
<li><p><strong>Wrongfully Accused by an Algorithm</strong>: In what may be the first known case of its kind, a faulty facial recognition match
led to a Michigan man’s arrest for a crime he did not commit. – NYTimes <a class="bibtex reference internal" href="../09_appendix/lit_review.html#hill-2020" id="id1">[Hil20]</a></p></li>
<li><p><strong>Amazon ditched AI recruiting tool that favored men for technical jobs</strong>. – The Guardian <a class="bibtex reference internal" href="#reuters-2018" id="id2">[Reu18]</a></p></li>
<li><p><strong>Police officers raise concerns about ‘biased’ AI data</strong>. – BBC News <a class="bibtex reference internal" href="#bbc-news-2019" id="id3">[bbc19]</a></p></li>
</ul>
<p>But how does this happen?
A prediction model has to be designed and there are a number of legal and moral obstacles to prevent a group/individual from purposefully designing a biased system.
However, even for the best intentioned there are a number of potential problems.
Examples of these problems include (but are not limited to):</p>
<ul class="simple">
<li><p><em>The tyranny of the majority:</em> We optimise to be right for the many, at the expense of minority groups.</p></li>
<li><p><em>Sampling bias:</em> We don’t have representative data of our population.</p></li>
<li><p><em>Proxy labels:</em> We don’t (or can’t) measure what we truly want to measure, so use a related quality as a proxy.</p></li>
<li><p><em>Biased data:</em> The recorded human decision was just plain biased.</p></li>
</ul>
<p>And unfortunately these aren’t mutually exclusive.</p>
<p>An unconstrained machine learning model is susceptible to all of these problems.
To face this challenge, the machine learning community has focused on creating a class of learning models that are constrained
to exhibit less bias than an unconstrained model.
Typically, these are referred to as “Fair Machine Learning Models”.</p>
<div class="section" id="fair-machine-learning">
<h3>Fair Machine Learning<a class="headerlink" href="#fair-machine-learning" title="Permalink to this headline">¶</a></h3>
<p>Fair Machine Learning, in general, aims to resolve “unfairness” (or the effect of bias) by affecting a model in one of
three places in the general learning pipeline.</p>
<ol class="simple">
<li><p>Pre-model training.</p>
<ul class="simple">
<li><p>Using a model to reduce bias in the underlying data, so that an unconstrained downstream classifier will exhibit fairer outcomes.</p></li>
</ul>
</li>
<li><p>During model training.</p>
<ul class="simple">
<li><p>Adding constraints to a model so that breaches in these constraints are heavily penalised during training.</p></li>
</ul>
</li>
<li><p>Post-model training.</p>
<ul class="simple">
<li><p>Adjusting the output of an unconstrained model so that the adjusted outputs don’t breach a given constraint.</p></li>
</ul>
</li>
</ol>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This comparison is of course a little over-simplistic.
This will be expanded on in the introduction to my thesis.</p>
</div>
</div>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Approach</p></th>
<th class="text-align:center head"><p>Multi-task support</p></th>
<th class="text-align:center head"><p>Task model Agnostic</p></th>
<th class="text-align:center head"><p>Pareto-optimal</p></th>
<th class="text-align:center head"><p>Constraints guaranteed to be enforced</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Pre-process</p></td>
<td class="text-align:center"><p>X</p></td>
<td class="text-align:center"><p>X</p></td>
<td class="text-align:center"><p></p></td>
<td class="text-align:center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>During</p></td>
<td class="text-align:center"><p></p></td>
<td class="text-align:center"><p></p></td>
<td class="text-align:center"><p>X</p></td>
<td class="text-align:center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Post-process</p></td>
<td class="text-align:center"><p></p></td>
<td class="text-align:center"><p>X</p></td>
<td class="text-align:center"><p></p></td>
<td class="text-align:center"><p>X</p></td>
</tr>
</tbody>
</table>
<p>In my work I focus on removing bias in the ‘pre-processing’ stage.
This is an exciting and active research area with spotlight tutorials at top conferences such as NeurIPS<a class="footnote-reference brackets" href="#footnote" id="id4">1</a> <a class="bibtex reference internal" href="#foundation" id="id5">[Fou]</a>.
Part of the reason for the excitement in this area is that the underlying data itself is a major source of bias.
After all, this is what a model is using to determine “correct” behaviour.
If we are able to understand and counteract bias that exists in the underlying data, then we can use an unconstrained
classifier (which may already have been heavily invested in) for a task.
Crucially, we may be potentially able to use the same data for performing <em>multiple fair tasks</em>.</p>
<p>Ultimately though, even a model counteracting bias will not be fully trusted without being able to interpret the actions
that it has taken to counteract bias.
Simply off-loading a problem from one black-box to another only masks the issue.
My work specifically deals with <em>this</em> problem.</p>
<p>This work focuses on working with data, which is imperfect, but readily available, and asks:</p>
<p>Given some data, can we use machine learning to understand what changes need to made to counteract a specific bias?</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>I’m aware that this research question isn’t firm enough, but I’m having trouble articulating it.
Advice on this would be appreciated.</p>
</div>
</div>
</div>
</div>
<div class="section" id="research-question">
<h2>Research Question<a class="headerlink" href="#research-question" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>Can we learn a representation of data that makes downstream tasks <strong>fair</strong>?</p>
<ol class="simple">
<li><p>If so, can we understand what the representation <strong>changed</strong>?</p></li>
</ol>
</li>
</ol>
<p>I will answer this question by:</p>
<ul class="simple">
<li><p>demonstrating that fair representations of data can be built in the original data domain without loss of performance with regard to both utility and fairness criterion.</p></li>
<li><p>demonstrating qualitatively that representations in the data domain provide feedback as to what is required to make data “fair”.</p></li>
</ul>
<p id="bibtex-bibliography-content/00_annual_review/area-0"><dl class="citation">
<dt class="bibtex label" id="bbc-news-2019"><span class="brackets"><a class="fn-backref" href="#id3">bbc19</a></span></dt>
<dd><p>Police officers raise concerns about ‘biased’ ai data. Sep 2019. URL: <a class="reference external" href="https://www.bbc.co.uk/news/technology-49717378">https://www.bbc.co.uk/news/technology-49717378</a>.</p>
</dd>
<dt class="bibtex label" id="foundation"><span class="brackets"><a class="fn-backref" href="#id5">Fou</a></span></dt>
<dd><p>Neural Information Processing Systems Foundation. URL: <a class="reference external" href="https://neurips.cc/Conferences/2019/Schedule?showEvent=13212">https://neurips.cc/Conferences/2019/Schedule?showEvent=13212</a>.</p>
</dd>
<dt class="bibtex label" id="hill-2020"><span class="brackets"><a class="fn-backref" href="#id1">Hil20</a></span></dt>
<dd><p>Kashmir Hill. Wrongfully accused by an algorithm. Jun 2020. URL: <a class="reference external" href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html">https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html</a>.</p>
</dd>
<dt class="bibtex label" id="reuters-2018"><span class="brackets"><a class="fn-backref" href="#id2">Reu18</a></span></dt>
<dd><p>Reuters. Amazon ditched ai recruiting tool that favored men for technical jobs. Oct 2018. URL: <a class="reference external" href="https://www.theguardian.com/technology/2018/oct/10/amazon-hiring-ai-gender-bias-recruiting-engine">https://www.theguardian.com/technology/2018/oct/10/amazon-hiring-ai-gender-bias-recruiting-engine</a>.</p>
</dd>
</dl>
</p>
<hr class="docutils" />
<dl class="footnote brackets">
<dt class="label" id="footnote"><span class="brackets"><a class="fn-backref" href="#id4">1</a></span></dt>
<dd><p>http://sanmi.cs.illinois.edu/documents/Representation_Learning_Fairness_NeurIPS19_Tutorial.pdf</p>
</dd>
</dl>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="summary.html" title="previous page">Summary</a>
    <a class='right-next' id="next-link" href="activities_to_date.html" title="next page">Activities to date</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Oliver Thomas<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-170288604-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>